# Example pwm configuration file
#
# This file can be placed at:
# - Global: ~/.config/pwm/config.toml (user-wide defaults)
# - Project: <repo>/.pwm.toml (project-specific settings)
#
# Project config overrides global config.
# Environment variables override both.

[jira]
# Jira connection settings (recommended to use environment variables instead)
# base_url = "https://your-domain.atlassian.net"
# email = "your.email@example.com"
# token = "your-api-token"  # DO NOT commit this

# Project key
project_key = "ABC"

[jira.issue_defaults]
# Default issue type when creating new issues
issue_type = "Story"

# Default labels (comma-separated in prompts, array in config)
labels = ["backend", "api"]

# Custom field defaults - useful for required fields in your Jira project
# Find custom field IDs by looking at Jira API responses or checking field settings
# Format: customfield_XXXXX = value (string, object, or array depending on field type)

# Example: Single-select custom field (like "Responsible Team")
[jira.issue_defaults.custom_fields.customfield_10370]
value = "Platform Team"

# Example: String custom field
# customfield_12345 = "Default value"

# Example: Multi-select custom field
# customfield_67890 = [{ value = "Option1" }, { value = "Option2" }]

[github]
# GitHub repo (org/repo format)
repo = "myorg/myrepo"

[github.pr_defaults]
# Default reviewers for pull requests (used with pwm work-end --request-review)
reviewers = ["teammate1", "teammate2"]
team_reviewers = ["platform-team"]

[branch]
# Branch naming pattern
# Available placeholders: {issue_key}, {slug}
# {slug} is auto-generated from issue summary
pattern = "{issue_key}-{slug}"

[git]
# Default remote name
default_remote = "origin"

[openai]
# OpenAI API configuration (optional - for AI-powered summaries)
# Recommended to use environment variable: PWM_OPENAI_API_KEY or OPENAI_API_KEY
# api_key = "sk-..."  # DO NOT commit this

# Model to use for summarization (default: gpt-4o-mini for cost efficiency)
# Options: gpt-4o-mini (~$1-3/month), gpt-4o (~$50-150/month), gpt-4-turbo
model = "gpt-4o-mini"

# Base URL (for Azure OpenAI or custom endpoints)
# base_url = "https://api.openai.com/v1"

# Generation parameters
max_tokens = 500      # Maximum tokens in response
temperature = 0.7     # Creativity (0.0-2.0, higher = more creative)
